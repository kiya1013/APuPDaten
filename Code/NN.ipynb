{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training a CNN on CIFAR10\n",
    "=====================\n",
    "\n",
    "In this notebook we use a CNN to train a model on the CIFAR10 dataset. \n",
    "This notebook follows the official PyTorch CNN tutorial which you can find [here](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(prediction, truth):\n",
    "    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n",
    "    tensors, i.e. the amount of positions where the values of `prediction`\n",
    "    and `truth` are\n",
    "    - 1 and 1 (True Positive)\n",
    "    - 1 and 0 (False Positive)\n",
    "    - 0 and 0 (True Negative)\n",
    "    - 0 and 1 (False Negative)\n",
    "    \"\"\"\n",
    "\n",
    "    confusion_vector = prediction / truth\n",
    "    # Element-wise division of the 2 tensors returns a new tensor which holds a\n",
    "    # unique value for each case:\n",
    "    #   1     where prediction and truth are 1 (True Positive)\n",
    "    #   inf   where prediction is 1 and truth is 0 (False Positive)\n",
    "    #   nan   where prediction and truth are 0 (True Negative)\n",
    "    #   0     where prediction is 0 and truth is 1 (False Negative)\n",
    "\n",
    "    true_positives = torch.sum(confusion_vector == 1).item()\n",
    "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
    "\n",
    "    return true_positives, false_positives, true_negatives, false_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('..\\\\Data\\\\data_01_clean.csv',index_col='Unnamed: 0')\n",
    "\n",
    "X=df.drop(columns=['Dev'])\n",
    "y= df['Dev']\n",
    "\n",
    "X = X.values # to numpy-array\n",
    "y = y.values # to numpy-array\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset=list(zip(X_train,y_train))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset=list(zip(X_test,y_test))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('normal','Anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class DeepNeuralNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.hidden1 = nn.Linear(39, 4096)\n",
    "#         self.hidden2 = nn.Linear(4096, 1000)\n",
    "#         self.hidden3 = nn.Linear(1000, 2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         z1 = self.hidden1(x)\n",
    "#         a1 = torch.sigmoid(z1)\n",
    "#         z2 = self.hidden2(a1)\n",
    "#         a2 = torch.sigmoid(z2)\n",
    "#         z3 = self.hidden3(a2)\n",
    "#         return z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(39, 4096)\n",
    "        self.hidden2 = nn.Linear(4096, 8192)\n",
    "        self.hidden3 = nn.Linear(8192, 1000)\n",
    "        self.hidden4 = nn.Linear(1000, 100)\n",
    "        self.hidden5 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        z1 = self.hidden1(x)\n",
    "        a1 = torch.sigmoid(z1)\n",
    "        z2 = self.hidden2(a1)\n",
    "        a2 = torch.sigmoid(z2)\n",
    "        z3 = self.hidden3(a2)\n",
    "        a3 = torch.sigmoid(z3)\n",
    "        z4 = self.hidden4(a3)\n",
    "        a4 = torch.sigmoid(z4)\n",
    "        z5 = self.hidden5(a4)\n",
    "        return z5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.389\n",
      "[1,  4000] loss: 0.408\n",
      "[1,  6000] loss: 0.396\n",
      "[1,  8000] loss: 0.387\n",
      "[1, 10000] loss: 0.389\n",
      "[1, 12000] loss: 0.391\n",
      "[1, 14000] loss: 0.391\n",
      "[1, 16000] loss: 0.389\n",
      "[1, 18000] loss: 0.401\n",
      "[1, 20000] loss: 0.392\n",
      "[1, 22000] loss: 0.399\n",
      "[1, 24000] loss: 0.391\n",
      "[1, 26000] loss: 0.397\n",
      "[1, 28000] loss: 0.380\n",
      "[1, 30000] loss: 0.405\n",
      "[1, 32000] loss: 0.405\n",
      "[1, 34000] loss: 0.400\n",
      "[1, 36000] loss: 0.396\n",
      "[1, 38000] loss: 0.403\n",
      "[1, 40000] loss: 0.393\n",
      "[1, 42000] loss: 0.379\n",
      "[1, 44000] loss: 0.401\n",
      "[1, 46000] loss: 0.391\n",
      "[1, 48000] loss: 0.386\n",
      "[1, 50000] loss: 0.398\n",
      "[2,  2000] loss: 0.405\n",
      "[2,  4000] loss: 0.391\n",
      "[2,  6000] loss: 0.390\n",
      "[2,  8000] loss: 0.385\n",
      "[2, 10000] loss: 0.392\n",
      "[2, 12000] loss: 0.396\n",
      "[2, 14000] loss: 0.398\n",
      "[2, 16000] loss: 0.386\n",
      "[2, 18000] loss: 0.375\n",
      "[2, 20000] loss: 0.386\n",
      "[2, 22000] loss: 0.393\n",
      "[2, 24000] loss: 0.389\n",
      "[2, 26000] loss: 0.390\n",
      "[2, 28000] loss: 0.397\n",
      "[2, 30000] loss: 0.393\n",
      "[2, 32000] loss: 0.379\n",
      "[2, 34000] loss: 0.372\n",
      "[2, 36000] loss: 0.388\n",
      "[2, 38000] loss: 0.377\n",
      "[2, 40000] loss: 0.376\n",
      "[2, 42000] loss: 0.351\n",
      "[2, 44000] loss: 0.355\n",
      "[2, 46000] loss: 0.340\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "net = DeepNeuralNetwork()\n",
    "net = net.float()\n",
    "net.to(device)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracy = []\n",
    "test_accuracy  = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(15):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs.to(device) #needed when using gpu\n",
    "        labels = labels.to(device) #needed when using gpu\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            train_losses.append(running_loss / 2000)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        correct = 0\n",
    "        \n",
    "       \n",
    "#---------------------------Test---Testing----------------------------------------------------------\n",
    "    net.eval()   \n",
    "     \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device) #needed when using gpu\n",
    "            labels = labels.to(device) #needed when using gpu\n",
    "            \n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images.float())\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            predicted = torch.argmax(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            test_accuracy.append(confusion(predicted, labels)+(epoch+1,))\n",
    "\n",
    "    \n",
    "#---------------------------Train---Testing----------------------------------------------------------\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device) #needed when using gpu\n",
    "            labels = labels.to(device) #needed when using gpu\n",
    "            \n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images.float())\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            predicted = torch.argmax(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            train_accuracy.append(confusion(predicted, labels)+(epoch+1,))\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "print(f'Time: {time.time() - start_time:.1f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ae091c54f0>]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label= \"Training losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41382</td>\n",
       "      <td>3921</td>\n",
       "      <td>2724</td>\n",
       "      <td>1973</td>\n",
       "      <td>0.88212</td>\n",
       "      <td>0.954492</td>\n",
       "      <td>0.913449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>41972</td>\n",
       "      <td>4514</td>\n",
       "      <td>2131</td>\n",
       "      <td>1383</td>\n",
       "      <td>0.88206</td>\n",
       "      <td>0.968101</td>\n",
       "      <td>0.902895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>43099</td>\n",
       "      <td>6177</td>\n",
       "      <td>468</td>\n",
       "      <td>256</td>\n",
       "      <td>0.87134</td>\n",
       "      <td>0.994095</td>\n",
       "      <td>0.874645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>42908</td>\n",
       "      <td>4996</td>\n",
       "      <td>1649</td>\n",
       "      <td>447</td>\n",
       "      <td>0.89114</td>\n",
       "      <td>0.989690</td>\n",
       "      <td>0.895708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42152</td>\n",
       "      <td>4198</td>\n",
       "      <td>2447</td>\n",
       "      <td>1203</td>\n",
       "      <td>0.89198</td>\n",
       "      <td>0.972252</td>\n",
       "      <td>0.909428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>42395</td>\n",
       "      <td>3645</td>\n",
       "      <td>3000</td>\n",
       "      <td>960</td>\n",
       "      <td>0.90790</td>\n",
       "      <td>0.977857</td>\n",
       "      <td>0.920830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>41361</td>\n",
       "      <td>2387</td>\n",
       "      <td>4258</td>\n",
       "      <td>1994</td>\n",
       "      <td>0.91238</td>\n",
       "      <td>0.954008</td>\n",
       "      <td>0.945438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>40648</td>\n",
       "      <td>1884</td>\n",
       "      <td>4761</td>\n",
       "      <td>2707</td>\n",
       "      <td>0.90818</td>\n",
       "      <td>0.937562</td>\n",
       "      <td>0.955704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>42272</td>\n",
       "      <td>3341</td>\n",
       "      <td>3304</td>\n",
       "      <td>1083</td>\n",
       "      <td>0.91152</td>\n",
       "      <td>0.975020</td>\n",
       "      <td>0.926753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>42612</td>\n",
       "      <td>3625</td>\n",
       "      <td>3020</td>\n",
       "      <td>743</td>\n",
       "      <td>0.91264</td>\n",
       "      <td>0.982862</td>\n",
       "      <td>0.921600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>41308</td>\n",
       "      <td>2718</td>\n",
       "      <td>3927</td>\n",
       "      <td>2047</td>\n",
       "      <td>0.90470</td>\n",
       "      <td>0.952785</td>\n",
       "      <td>0.938264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>41919</td>\n",
       "      <td>2778</td>\n",
       "      <td>3867</td>\n",
       "      <td>1436</td>\n",
       "      <td>0.91572</td>\n",
       "      <td>0.966878</td>\n",
       "      <td>0.937848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>42146</td>\n",
       "      <td>3068</td>\n",
       "      <td>3577</td>\n",
       "      <td>1209</td>\n",
       "      <td>0.91446</td>\n",
       "      <td>0.972114</td>\n",
       "      <td>0.932145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  true_positives  false_positives  true_negatives  false_negatives  \\\n",
       "0       1           41382             3921            2724             1973   \n",
       "1       2           41972             4514            2131             1383   \n",
       "2       3           43099             6177             468              256   \n",
       "3       4           42908             4996            1649              447   \n",
       "4       5           42152             4198            2447             1203   \n",
       "5       6           42395             3645            3000              960   \n",
       "6       7           41361             2387            4258             1994   \n",
       "7       8           40648             1884            4761             2707   \n",
       "8       9           42272             3341            3304             1083   \n",
       "9      10           42612             3625            3020              743   \n",
       "10     11           41308             2718            3927             2047   \n",
       "11     12           41919             2778            3867             1436   \n",
       "12     13           42146             3068            3577             1209   \n",
       "\n",
       "    accuracy    recall  precission  \n",
       "0    0.88212  0.954492    0.913449  \n",
       "1    0.88206  0.968101    0.902895  \n",
       "2    0.87134  0.994095    0.874645  \n",
       "3    0.89114  0.989690    0.895708  \n",
       "4    0.89198  0.972252    0.909428  \n",
       "5    0.90790  0.977857    0.920830  \n",
       "6    0.91238  0.954008    0.945438  \n",
       "7    0.90818  0.937562    0.955704  \n",
       "8    0.91152  0.975020    0.926753  \n",
       "9    0.91264  0.982862    0.921600  \n",
       "10   0.90470  0.952785    0.938264  \n",
       "11   0.91572  0.966878    0.937848  \n",
       "12   0.91446  0.972114    0.932145  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(test_accuracy,columns=['true_positives', 'false_positives', 'true_negatives', 'false_negatives','epoch'])\n",
    "res_df=res_df.groupby('epoch').agg({'true_positives':'sum', 'false_positives':'sum', 'true_negatives':'sum', 'false_negatives':'sum'}).reset_index()\n",
    "res_df['accuracy']=(res_df['true_positives']+res_df['true_negatives'])/X_test.shape[0]\n",
    "res_df['recall']=res_df['true_positives']/(res_df['true_positives']+res_df['false_negatives'])\n",
    "res_df['precission']=res_df['true_positives']/(res_df['true_positives']+res_df['false_positives'])\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>165234</td>\n",
       "      <td>15888</td>\n",
       "      <td>10792</td>\n",
       "      <td>8086</td>\n",
       "      <td>0.880130</td>\n",
       "      <td>0.953346</td>\n",
       "      <td>0.912280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>167798</td>\n",
       "      <td>18100</td>\n",
       "      <td>8580</td>\n",
       "      <td>5522</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.968140</td>\n",
       "      <td>0.902635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>172432</td>\n",
       "      <td>24722</td>\n",
       "      <td>1958</td>\n",
       "      <td>888</td>\n",
       "      <td>0.871950</td>\n",
       "      <td>0.994877</td>\n",
       "      <td>0.874606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>171488</td>\n",
       "      <td>20008</td>\n",
       "      <td>6672</td>\n",
       "      <td>1832</td>\n",
       "      <td>0.890800</td>\n",
       "      <td>0.989430</td>\n",
       "      <td>0.895517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>168476</td>\n",
       "      <td>16740</td>\n",
       "      <td>9940</td>\n",
       "      <td>4844</td>\n",
       "      <td>0.892080</td>\n",
       "      <td>0.972052</td>\n",
       "      <td>0.909619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>169487</td>\n",
       "      <td>14660</td>\n",
       "      <td>12020</td>\n",
       "      <td>3833</td>\n",
       "      <td>0.907535</td>\n",
       "      <td>0.977885</td>\n",
       "      <td>0.920390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>165304</td>\n",
       "      <td>9866</td>\n",
       "      <td>16814</td>\n",
       "      <td>8016</td>\n",
       "      <td>0.910590</td>\n",
       "      <td>0.953750</td>\n",
       "      <td>0.943678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>162393</td>\n",
       "      <td>7887</td>\n",
       "      <td>18793</td>\n",
       "      <td>10927</td>\n",
       "      <td>0.905930</td>\n",
       "      <td>0.936955</td>\n",
       "      <td>0.953682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>169069</td>\n",
       "      <td>13551</td>\n",
       "      <td>13129</td>\n",
       "      <td>4251</td>\n",
       "      <td>0.910990</td>\n",
       "      <td>0.975473</td>\n",
       "      <td>0.925797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>170337</td>\n",
       "      <td>14718</td>\n",
       "      <td>11962</td>\n",
       "      <td>2983</td>\n",
       "      <td>0.911495</td>\n",
       "      <td>0.982789</td>\n",
       "      <td>0.920467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>165168</td>\n",
       "      <td>11270</td>\n",
       "      <td>15410</td>\n",
       "      <td>8152</td>\n",
       "      <td>0.902890</td>\n",
       "      <td>0.952966</td>\n",
       "      <td>0.936125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>167577</td>\n",
       "      <td>11398</td>\n",
       "      <td>15282</td>\n",
       "      <td>5743</td>\n",
       "      <td>0.914295</td>\n",
       "      <td>0.966865</td>\n",
       "      <td>0.936315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>168523</td>\n",
       "      <td>12484</td>\n",
       "      <td>14196</td>\n",
       "      <td>4797</td>\n",
       "      <td>0.913595</td>\n",
       "      <td>0.972323</td>\n",
       "      <td>0.931030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  true_positives  false_positives  true_negatives  false_negatives  \\\n",
       "0       1          165234            15888           10792             8086   \n",
       "1       2          167798            18100            8580             5522   \n",
       "2       3          172432            24722            1958              888   \n",
       "3       4          171488            20008            6672             1832   \n",
       "4       5          168476            16740            9940             4844   \n",
       "5       6          169487            14660           12020             3833   \n",
       "6       7          165304             9866           16814             8016   \n",
       "7       8          162393             7887           18793            10927   \n",
       "8       9          169069            13551           13129             4251   \n",
       "9      10          170337            14718           11962             2983   \n",
       "10     11          165168            11270           15410             8152   \n",
       "11     12          167577            11398           15282             5743   \n",
       "12     13          168523            12484           14196             4797   \n",
       "\n",
       "    accuracy    recall  precission  \n",
       "0   0.880130  0.953346    0.912280  \n",
       "1   0.881890  0.968140    0.902635  \n",
       "2   0.871950  0.994877    0.874606  \n",
       "3   0.890800  0.989430    0.895517  \n",
       "4   0.892080  0.972052    0.909619  \n",
       "5   0.907535  0.977885    0.920390  \n",
       "6   0.910590  0.953750    0.943678  \n",
       "7   0.905930  0.936955    0.953682  \n",
       "8   0.910990  0.975473    0.925797  \n",
       "9   0.911495  0.982789    0.920467  \n",
       "10  0.902890  0.952966    0.936125  \n",
       "11  0.914295  0.966865    0.936315  \n",
       "12  0.913595  0.972323    0.931030  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(train_accuracy,columns=['true_positives', 'false_positives', 'true_negatives', 'false_negatives','epoch'])\n",
    "res_df=res_df.groupby('epoch').agg({'true_positives':'sum', 'false_positives':'sum', 'true_negatives':'sum', 'false_negatives':'sum'}).reset_index()\n",
    "res_df['accuracy']=(res_df['true_positives']+res_df['true_negatives'])/X_train.shape[0]\n",
    "res_df['recall']=res_df['true_positives']/(res_df['true_positives']+res_df['false_negatives'])\n",
    "res_df['precission']=res_df['true_positives']/(res_df['true_positives']+res_df['false_positives'])\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-153-759c4c5efcf3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-153-759c4c5efcf3>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    ----\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test data: 92 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device) #needed when using gpu\n",
    "        labels = labels.to(device) #needed when using gpu\n",
    "        \n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images.float())\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        predicted = torch.argmax(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test data: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train data: 91 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device) #needed when using gpu\n",
    "        labels = labels.to(device) #needed when using gpu\n",
    "        \n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images.float())\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        predicted = torch.argmax(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the train data: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
